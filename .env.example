# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3:latest

# Optional: OpenAI API Key (if you want to use OpenAI as well)
# OPENAI_API_KEY=your_api_key_here

# RLM Configuration
RLM_MAX_ITERATIONS=50
RLM_MAX_RECURSION_DEPTH=1
RLM_VERBOSE=true
RLM_LOG_DIR=./logs
